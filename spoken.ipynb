{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def feature_extraction(file_path):\n",
        "    # Load your audio file\n",
        "    y, sr = librosa.load(file_path)\n",
        "\n",
        "    pre_emphasis = 0.97\n",
        "    # Pre-emphasis\n",
        "    y = np.append(y[0], y[1:] - pre_emphasis * y[:-1])\n",
        "\n",
        "    window_size = 0.025  # 25ms window size\n",
        "    hop_size = 0.010  # 10ms hop size\n",
        "    # Window and hop length in samples\n",
        "    n_fft = int(window_size * sr)  # 25ms window size\n",
        "    hop_length = int(hop_size * sr)  # 10ms hop size\n",
        "\n",
        "    # Compute the Short-Time Fourier Transform (STFT)\n",
        "    Short_Time_Fourier_Transform = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)\n",
        "    S, _ = librosa.magphase(Short_Time_Fourier_Transform)\n",
        "\n",
        "    # Compute the energy feature from the magnitude spectrogram\n",
        "    energy = librosa.feature.rms(S=S, frame_length=n_fft, hop_length=hop_length)\n",
        "\n",
        "    # Extract the Mel filter bank features and compute log-mel spectrogram\n",
        "    mel_filter_spectrogram = librosa.feature.melspectrogram(S=S, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
        "    log_mel_spectrogram = librosa.power_to_db(mel_filter_spectrogram)\n",
        "\n",
        "    # Extract 12 MFCCs (excluding the 0th coefficient)\n",
        "    mfccs = librosa.feature.mfcc(S=log_mel_spectrogram, sr=sr, n_mfcc=12)\n",
        "\n",
        "    # Calculate the delta and delta-delta features for MFCCs\n",
        "    delta_mfccs = librosa.feature.delta(mfccs, order=1)\n",
        "    double_delta_mfccs = librosa.feature.delta(mfccs, order=2)\n",
        "\n",
        "    # Calculate the delta and delta-delta for energy\n",
        "    delta_energy = librosa.feature.delta(energy, order=1)\n",
        "    double_delta_energy = librosa.feature.delta(energy, order=2)\n",
        "\n",
        "    # Concatenate MFCCs and energy along with their delta and delta-delta features\n",
        "    combined_features = np.vstack([\n",
        "        mfccs,\n",
        "        energy,\n",
        "        delta_mfccs,\n",
        "        delta_energy,\n",
        "        double_delta_mfccs,\n",
        "        double_delta_energy\n",
        "    ])\n",
        "\n",
        "    # Ensure you have 39 total features: 13 (12 MFCC + 1 energy) * 3 = 39\n",
        "    assert combined_features.shape[0] == 39, f\"Number of features does not match 39, but {combined_features.shape[0]}\"\n",
        "\n",
        "    return combined_features\n",
        "\n",
        "root_dir = ['/content/drive/My Drive/training data', '/content/drive/My Drive/testing data']\n",
        "for root in  root_dir:\n",
        "    # Iterate through all directories and files\n",
        "    for subdir, dirs, files in os.walk(root):\n",
        "\n",
        "\n",
        "        for file in files:\n",
        "            if file.endswith('.wav'):\n",
        "                filepath = os.path.join(subdir, file)\n",
        "                print(f'Processing {filepath}')\n",
        "                features = feature_extraction(filepath)\n",
        "\n",
        "                print(features.shape)\n",
        "\n",
        "\n",
        "                # Save features to CSV\n",
        "\n",
        "                feature_df = pd.DataFrame(features).T  # Transpose to have frames as rows\n",
        "                csv_filename = os.path.splitext(filepath)[0] + '_features.csv'\n",
        "                feature_df.to_csv(csv_filename, index=False)\n",
        "                print(f'Saved features to {csv_filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOSjMu6T7iFU",
        "outputId": "439c8162-9c58-48d3-ea45-344ab1c8f096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_train043.wav\n",
            "(39, 12120)\n",
            "Saved features to /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_train043_features.csv\n",
            "Processing /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_train042.wav\n",
            "(39, 1441)\n",
            "Saved features to /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_train042_features.csv\n",
            "Processing /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_train041.wav\n",
            "(39, 4878)\n",
            "Saved features to /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_train041_features.csv\n",
            "Processing /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_test025.wav\n",
            "(39, 3444)\n",
            "Saved features to /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_test025_features.csv\n",
            "Processing /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_test024.wav\n",
            "(39, 2258)\n",
            "Saved features to /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_test024_features.csv\n",
            "Processing /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_test023.wav\n",
            "(39, 3552)\n",
            "Saved features to /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_test023_features.csv\n",
            "Processing /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_test022.wav\n",
            "(39, 3949)\n",
            "Saved features to /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_test022_features.csv\n",
            "Processing /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_test021.wav\n",
            "(39, 3774)\n",
            "Saved features to /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_test021_features.csv\n",
            "Processing /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_train045.wav\n",
            "(39, 2070)\n",
            "Saved features to /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_train045_features.csv\n",
            "Processing /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_train044.wav\n",
            "(39, 6647)\n",
            "Saved features to /content/drive/My Drive/training data/Ramallah_Reef/ramallah-reef_train044_features.csv\n",
            "Processing /content/drive/My Drive/training data/Nablus/nablus_test021.wav\n",
            "(39, 14363)\n",
            "Saved features to /content/drive/My Drive/training data/Nablus/nablus_test021_features.csv\n",
            "Processing /content/drive/My Drive/training data/Nablus/nablus_test025.wav\n",
            "(39, 3542)\n",
            "Saved features to /content/drive/My Drive/training data/Nablus/nablus_test025_features.csv\n",
            "Processing /content/drive/My Drive/training data/Nablus/nablus_test024.wav\n",
            "(39, 3529)\n",
            "Saved features to /content/drive/My Drive/training data/Nablus/nablus_test024_features.csv\n",
            "Processing /content/drive/My Drive/training data/Nablus/nablus_test023.wav\n",
            "(39, 3250)\n",
            "Saved features to /content/drive/My Drive/training data/Nablus/nablus_test023_features.csv\n",
            "Processing /content/drive/My Drive/training data/Nablus/nablus_test022.wav\n",
            "(39, 4497)\n",
            "Saved features to /content/drive/My Drive/training data/Nablus/nablus_test022_features.csv\n",
            "Processing /content/drive/My Drive/training data/Nablus/nablus_train044.wav\n",
            "(39, 44124)\n",
            "Saved features to /content/drive/My Drive/training data/Nablus/nablus_train044_features.csv\n",
            "Processing /content/drive/My Drive/training data/Nablus/nablus_train043.wav\n",
            "(39, 8861)\n",
            "Saved features to /content/drive/My Drive/training data/Nablus/nablus_train043_features.csv\n",
            "Processing /content/drive/My Drive/training data/Nablus/nablus_train042.wav\n",
            "(39, 13600)\n",
            "Saved features to /content/drive/My Drive/training data/Nablus/nablus_train042_features.csv\n",
            "Processing /content/drive/My Drive/training data/Nablus/nablus_train041.wav\n",
            "(39, 151976)\n",
            "Saved features to /content/drive/My Drive/training data/Nablus/nablus_train041_features.csv\n",
            "Processing /content/drive/My Drive/training data/Nablus/nablus_train045.wav\n",
            "(39, 55497)\n",
            "Saved features to /content/drive/My Drive/training data/Nablus/nablus_train045_features.csv\n",
            "Processing /content/drive/My Drive/training data/Jerusalem/jerusalem_test023.wav\n",
            "(39, 3127)\n",
            "Saved features to /content/drive/My Drive/training data/Jerusalem/jerusalem_test023_features.csv\n",
            "Processing /content/drive/My Drive/training data/Jerusalem/jerusalem_test022.wav\n",
            "(39, 2544)\n",
            "Saved features to /content/drive/My Drive/training data/Jerusalem/jerusalem_test022_features.csv\n",
            "Processing /content/drive/My Drive/training data/Jerusalem/jerusalem_test021.wav\n",
            "(39, 3360)\n",
            "Saved features to /content/drive/My Drive/training data/Jerusalem/jerusalem_test021_features.csv\n",
            "Processing /content/drive/My Drive/training data/Jerusalem/jerusalem_train045.wav\n",
            "(39, 15048)\n",
            "Saved features to /content/drive/My Drive/training data/Jerusalem/jerusalem_train045_features.csv\n",
            "Processing /content/drive/My Drive/training data/Jerusalem/jerusalem_train044.wav\n",
            "(39, 5701)\n",
            "Saved features to /content/drive/My Drive/training data/Jerusalem/jerusalem_train044_features.csv\n",
            "Processing /content/drive/My Drive/training data/Jerusalem/jerusalem_train043.wav\n",
            "(39, 18016)\n",
            "Saved features to /content/drive/My Drive/training data/Jerusalem/jerusalem_train043_features.csv\n",
            "Processing /content/drive/My Drive/training data/Jerusalem/jerusalem_train042.wav\n",
            "(39, 4715)\n",
            "Saved features to /content/drive/My Drive/training data/Jerusalem/jerusalem_train042_features.csv\n",
            "Processing /content/drive/My Drive/training data/Jerusalem/jerusalem_train041.wav\n",
            "(39, 1997)\n",
            "Saved features to /content/drive/My Drive/training data/Jerusalem/jerusalem_train041_features.csv\n",
            "Processing /content/drive/My Drive/training data/Jerusalem/jerusalem_test025.wav\n",
            "(39, 1280)\n",
            "Saved features to /content/drive/My Drive/training data/Jerusalem/jerusalem_test025_features.csv\n",
            "Processing /content/drive/My Drive/training data/Jerusalem/jerusalem_test024.wav\n",
            "(39, 1379)\n",
            "Saved features to /content/drive/My Drive/training data/Jerusalem/jerusalem_test024_features.csv\n",
            "Processing /content/drive/My Drive/training data/Hebron/hebron_train041.wav\n",
            "(39, 48899)\n",
            "Saved features to /content/drive/My Drive/training data/Hebron/hebron_train041_features.csv\n",
            "Processing /content/drive/My Drive/training data/Hebron/hebron_test025.wav\n",
            "(39, 3249)\n",
            "Saved features to /content/drive/My Drive/training data/Hebron/hebron_test025_features.csv\n",
            "Processing /content/drive/My Drive/training data/Hebron/hebron_test024.wav\n",
            "(39, 7248)\n",
            "Saved features to /content/drive/My Drive/training data/Hebron/hebron_test024_features.csv\n",
            "Processing /content/drive/My Drive/training data/Hebron/hebron_test023.wav\n",
            "(39, 3272)\n",
            "Saved features to /content/drive/My Drive/training data/Hebron/hebron_test023_features.csv\n",
            "Processing /content/drive/My Drive/training data/Hebron/hebron_test022.wav\n",
            "(39, 2940)\n",
            "Saved features to /content/drive/My Drive/training data/Hebron/hebron_test022_features.csv\n",
            "Processing /content/drive/My Drive/training data/Hebron/hebron_test021.wav\n",
            "(39, 2529)\n",
            "Saved features to /content/drive/My Drive/training data/Hebron/hebron_test021_features.csv\n",
            "Processing /content/drive/My Drive/training data/Hebron/hebron_train045.wav\n",
            "(39, 6964)\n",
            "Saved features to /content/drive/My Drive/training data/Hebron/hebron_train045_features.csv\n",
            "Processing /content/drive/My Drive/training data/Hebron/hebron_train044.wav\n",
            "(39, 9682)\n",
            "Saved features to /content/drive/My Drive/training data/Hebron/hebron_train044_features.csv\n",
            "Processing /content/drive/My Drive/training data/Hebron/hebron_train043.wav\n",
            "(39, 8467)\n",
            "Saved features to /content/drive/My Drive/training data/Hebron/hebron_train043_features.csv\n",
            "Processing /content/drive/My Drive/training data/Hebron/hebron_train042.wav\n",
            "(39, 10172)\n",
            "Saved features to /content/drive/My Drive/training data/Hebron/hebron_train042_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Ramallah_Reef/ramallah-reef_train050.wav\n",
            "(39, 10166)\n",
            "Saved features to /content/drive/My Drive/testing data/Ramallah_Reef/ramallah-reef_train050_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Ramallah_Reef/ramallah-reef_train049.wav\n",
            "(39, 25191)\n",
            "Saved features to /content/drive/My Drive/testing data/Ramallah_Reef/ramallah-reef_train049_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Ramallah_Reef/ramallah-reef_train048.wav\n",
            "(39, 17317)\n",
            "Saved features to /content/drive/My Drive/testing data/Ramallah_Reef/ramallah-reef_train048_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Ramallah_Reef/ramallah-reef_train047.wav\n",
            "(39, 11047)\n",
            "Saved features to /content/drive/My Drive/testing data/Ramallah_Reef/ramallah-reef_train047_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Ramallah_Reef/ramallah-reef_train046.wav\n",
            "(39, 16156)\n",
            "Saved features to /content/drive/My Drive/testing data/Ramallah_Reef/ramallah-reef_train046_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Nablus/nablus_train046.wav\n",
            "(39, 10006)\n",
            "Saved features to /content/drive/My Drive/testing data/Nablus/nablus_train046_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Nablus/nablus_train049.wav\n",
            "(39, 22497)\n",
            "Saved features to /content/drive/My Drive/testing data/Nablus/nablus_train049_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Nablus/nablus_train048.wav\n",
            "(39, 3384)\n",
            "Saved features to /content/drive/My Drive/testing data/Nablus/nablus_train048_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Nablus/nablus_train047.wav\n",
            "(39, 8412)\n",
            "Saved features to /content/drive/My Drive/testing data/Nablus/nablus_train047_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Nablus/nablus_train050.wav\n",
            "(39, 13188)\n",
            "Saved features to /content/drive/My Drive/testing data/Nablus/nablus_train050_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Jerusalem/jerusalem_train047.wav\n",
            "(39, 41462)\n",
            "Saved features to /content/drive/My Drive/testing data/Jerusalem/jerusalem_train047_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Jerusalem/jerusalem_train046.wav\n",
            "(39, 11755)\n",
            "Saved features to /content/drive/My Drive/testing data/Jerusalem/jerusalem_train046_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Jerusalem/jerusalem_train049.wav\n",
            "(39, 61566)\n",
            "Saved features to /content/drive/My Drive/testing data/Jerusalem/jerusalem_train049_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Jerusalem/jerusalem_train048.wav\n",
            "(39, 9530)\n",
            "Saved features to /content/drive/My Drive/testing data/Jerusalem/jerusalem_train048_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Jerusalem/jerusalem_train050.wav\n",
            "(39, 11170)\n",
            "Saved features to /content/drive/My Drive/testing data/Jerusalem/jerusalem_train050_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Hebron/hebron_train046.wav\n",
            "(39, 7672)\n",
            "Saved features to /content/drive/My Drive/testing data/Hebron/hebron_train046_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Hebron/hebron_train048.wav\n",
            "(39, 945)\n",
            "Saved features to /content/drive/My Drive/testing data/Hebron/hebron_train048_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Hebron/hebron_train050.wav\n",
            "(39, 7829)\n",
            "Saved features to /content/drive/My Drive/testing data/Hebron/hebron_train050_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Hebron/hebron_train049.wav\n",
            "(39, 2078)\n",
            "Saved features to /content/drive/My Drive/testing data/Hebron/hebron_train049_features.csv\n",
            "Processing /content/drive/My Drive/testing data/Hebron/hebron_train047.wav\n",
            "(39, 9644)\n",
            "Saved features to /content/drive/My Drive/testing data/Hebron/hebron_train047_features.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Directory containing folders\n",
        "big_directorys = ['/content/drive/My Drive/training data/', '/content/drive/My Drive/testing data/']\n",
        "\n",
        "for big_directory in big_directorys:\n",
        "    # Initialize an empty list to store aggregated features and targets\n",
        "    all_data = []\n",
        "\n",
        "    # Iterate through each folder in the big directory\n",
        "    for folder_name in os.listdir(big_directory):\n",
        "        folder_path = os.path.join(big_directory, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            # Iterate through each file in the folder\n",
        "            for filename in os.listdir(folder_path):\n",
        "                if filename.endswith(\".csv\"):\n",
        "                    # Load the data\n",
        "                    file_path = os.path.join(folder_path, filename)\n",
        "                    df = pd.read_csv(file_path)\n",
        "\n",
        "                    # Aggregate Features\n",
        "                    mean_features = df.mean(axis=0)\n",
        "\n",
        "                    # Extract target from folder name\n",
        "                    target = folder_name\n",
        "\n",
        "                    # Append aggregated features and target to the list\n",
        "                    all_data.append(np.append(mean_features, target))\n",
        "\n",
        "    # Define column names for the DataFrame\n",
        "    num_features = len(mean_features)\n",
        "    columns = [f'Feature_{i+1}' for i in range(num_features)] + ['Target']\n",
        "\n",
        "    # Create DataFrame from the list\n",
        "    final_df = pd.DataFrame(all_data, columns=columns)\n",
        "\n",
        "\n",
        "    # Save aggregated features with targets into a single CSV file\n",
        "    output_file_path = os.path.join(big_directory, 'aggregated_features_with_targets.csv')\n",
        "    final_df.to_csv(output_file_path, index=False)"
      ],
      "metadata": {
        "id": "dTyX-fkVP_1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "# Read data from CSV file\n",
        "df = pd.read_csv('/content/drive/My Drive/training data/aggregated_features_with_targets.csv')\n",
        "dataSet = df.sample(frac=1, random_state=42) # Shuffle the data\n",
        "\n",
        "# Split columns between features and target\n",
        "training_features = dataSet.drop('Target', axis=1)\n",
        "training_target = dataSet['Target']\n",
        "\n"
      ],
      "metadata": {
        "id": "PbgHwwtrCw3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "dataSet = pd.read_csv('/content/drive/My Drive/testing data/aggregated_features_with_targets.csv')\n",
        "\n",
        "# Split columns between features and target\n",
        "testing_features = dataSet.drop('Target', axis=1)\n",
        "testing_target = dataSet['Target']\n"
      ],
      "metadata": {
        "id": "k4RV2RWdUaOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Applying the knn Classifier With K = 4 to the data\n",
        "knnClassifierWithK4 = KNeighborsClassifier(n_neighbors=4)\n",
        "knnClassifierWithK4.fit(training_features, training_target)\n",
        "\n",
        "# Predicting the test set results\n",
        "knnClassifierWithK4Predictions = knnClassifierWithK4.predict(testing_features)\n",
        "\n",
        "# Calculating the accuracy of the model\n",
        "knnClassifierWithK4Accuracy = accuracy_score(testing_target, knnClassifierWithK4Predictions)\n",
        "print(f'KNN Classifier with K=4 Accuracy: {knnClassifierWithK4Accuracy}')\n",
        "print(classification_report(testing_target, knnClassifierWithK4Predictions))\n",
        "# Print real and predicted labels\n",
        "for i in range(len(testing_target)):\n",
        "    print(f'Real: {testing_target[i]}, Predicted: {knnClassifierWithK4Predictions[i]}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSt8fxulbtsN",
        "outputId": "8ad2bced-42f4-4d83-c3c7-dc27ed50acef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Classifier with K=4 Accuracy: 0.25\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Hebron       0.25      0.40      0.31         5\n",
            "    Jerusalem       0.17      0.20      0.18         5\n",
            "       Nablus       1.00      0.20      0.33         5\n",
            "Ramallah_Reef       0.20      0.20      0.20         5\n",
            "\n",
            "     accuracy                           0.25        20\n",
            "    macro avg       0.40      0.25      0.26        20\n",
            " weighted avg       0.40      0.25      0.26        20\n",
            "\n",
            "Real: Ramallah_Reef, Predicted: Hebron\n",
            "Real: Ramallah_Reef, Predicted: Hebron\n",
            "Real: Ramallah_Reef, Predicted: Jerusalem\n",
            "Real: Ramallah_Reef, Predicted: Ramallah_Reef\n",
            "Real: Ramallah_Reef, Predicted: Hebron\n",
            "Real: Nablus, Predicted: Nablus\n",
            "Real: Nablus, Predicted: Jerusalem\n",
            "Real: Nablus, Predicted: Hebron\n",
            "Real: Nablus, Predicted: Jerusalem\n",
            "Real: Nablus, Predicted: Ramallah_Reef\n",
            "Real: Jerusalem, Predicted: Jerusalem\n",
            "Real: Jerusalem, Predicted: Hebron\n",
            "Real: Jerusalem, Predicted: Hebron\n",
            "Real: Jerusalem, Predicted: Ramallah_Reef\n",
            "Real: Jerusalem, Predicted: Ramallah_Reef\n",
            "Real: Hebron, Predicted: Hebron\n",
            "Real: Hebron, Predicted: Jerusalem\n",
            "Real: Hebron, Predicted: Hebron\n",
            "Real: Hebron, Predicted: Jerusalem\n",
            "Real: Hebron, Predicted: Ramallah_Reef\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Support Vector Machine (SVM)\n",
        "SVM = SVC()\n",
        "\n",
        "# Hyperparameters to test\n",
        "svm_parameters = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'degree': [2, 3, 4, 5]}\n",
        "\n",
        "# Grid Search with cross-validation\n",
        "svm_grid_search = GridSearchCV(estimator=SVM, param_grid=svm_parameters, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "svm_grid_search.fit(training_features, training_target)\n",
        "\n",
        "# Best parameters and score\n",
        "svm_best_params = svm_grid_search.best_params_\n",
        "svm_best_score = svm_grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters for SVM:\", svm_best_params)\n",
        "print(\"Best Cross-Validation Score:\", svm_best_score)\n",
        "\n",
        "best_svm_model = svm_grid_search.best_estimator_\n",
        "predictedTargetSVM = best_svm_model.predict(testing_features)\n",
        "accuracySVM = accuracy_score(testing_target, predictedTargetSVM)\n",
        "print(\"Accuracy of SVM :\", accuracySVM)\n",
        "print(classification_report(testing_target, predictedTargetSVM))\n",
        "\n",
        "# Print real and predicted labels\n",
        "for i in range(len(testing_target)):\n",
        "    print(f'Real: {testing_target[i]}, Predicted: {predictedTargetSVM[i]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5B8-hXagwgC",
        "outputId": "b5fc51f8-6eb3-4591-90f7-411b8764ace2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for SVM: {'degree': 2, 'kernel': 'linear'}\n",
            "Best Cross-Validation Score: 0.6\n",
            "Accuracy of SVM : 0.7\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Hebron       0.80      0.80      0.80         5\n",
            "    Jerusalem       0.83      1.00      0.91         5\n",
            "       Nablus       0.67      0.40      0.50         5\n",
            "Ramallah_Reef       0.50      0.60      0.55         5\n",
            "\n",
            "     accuracy                           0.70        20\n",
            "    macro avg       0.70      0.70      0.69        20\n",
            " weighted avg       0.70      0.70      0.69        20\n",
            "\n",
            "Real: Ramallah_Reef, Predicted: Ramallah_Reef\n",
            "Real: Ramallah_Reef, Predicted: Ramallah_Reef\n",
            "Real: Ramallah_Reef, Predicted: Ramallah_Reef\n",
            "Real: Ramallah_Reef, Predicted: Nablus\n",
            "Real: Ramallah_Reef, Predicted: Hebron\n",
            "Real: Nablus, Predicted: Nablus\n",
            "Real: Nablus, Predicted: Ramallah_Reef\n",
            "Real: Nablus, Predicted: Jerusalem\n",
            "Real: Nablus, Predicted: Nablus\n",
            "Real: Nablus, Predicted: Ramallah_Reef\n",
            "Real: Jerusalem, Predicted: Jerusalem\n",
            "Real: Jerusalem, Predicted: Jerusalem\n",
            "Real: Jerusalem, Predicted: Jerusalem\n",
            "Real: Jerusalem, Predicted: Jerusalem\n",
            "Real: Jerusalem, Predicted: Jerusalem\n",
            "Real: Hebron, Predicted: Hebron\n",
            "Real: Hebron, Predicted: Ramallah_Reef\n",
            "Real: Hebron, Predicted: Hebron\n",
            "Real: Hebron, Predicted: Hebron\n",
            "Real: Hebron, Predicted: Hebron\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Random Forest\n",
        "RFC = RandomForestClassifier()\n",
        "\n",
        "# Hyperparameters to test\n",
        "rfc_parameters = {\"n_estimators\": [10, 50, 100, 200], \"max_depth\": [5, 10, 20, 50]}\n",
        "\n",
        "# Grid Search with cross-validation\n",
        "RFC_classifier_grid_search = GridSearchCV(estimator=RFC, param_grid=rfc_parameters, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "RFC_classifier_grid_search.fit(training_features, training_target)\n",
        "\n",
        "# Best parameters and score\n",
        "RFC_best_params = RFC_classifier_grid_search.best_params_\n",
        "RFC_best_score = RFC_classifier_grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters for RFC:\", RFC_best_params)\n",
        "print(\"Best Cross-Validation Score:\", RFC_best_score)\n",
        "\n",
        "best_rfc_model = RFC_classifier_grid_search.best_estimator_\n",
        "predictedTargetRFC = best_rfc_model.predict(testing_features)\n",
        "accuracyRFC = accuracy_score(testing_target, predictedTargetRFC)\n",
        "\n",
        "print(\"Accuracy of RFC :\", accuracyRFC)\n",
        "print(classification_report(testing_target, predictedTargetRFC))\n",
        "\n",
        "\n",
        "# Print real and predicted labels\n",
        "for i in range(len(testing_target)):\n",
        "    print(f'Real: {testing_target[i]}, Predicted: {predictedTargetRFC[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHarQo6ScbYY",
        "outputId": "b8e5a190-622c-4192-d3ce-470b5e365aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters for RFC: {'max_depth': 5, 'n_estimators': 200}\n",
            "Best Cross-Validation Score: 0.65\n",
            "Accuracy of RFC : 0.3\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Hebron       0.30      0.60      0.40         5\n",
            "    Jerusalem       0.40      0.40      0.40         5\n",
            "       Nablus       0.50      0.20      0.29         5\n",
            "Ramallah_Reef       0.00      0.00      0.00         5\n",
            "\n",
            "     accuracy                           0.30        20\n",
            "    macro avg       0.30      0.30      0.27        20\n",
            " weighted avg       0.30      0.30      0.27        20\n",
            "\n",
            "Real: Ramallah_Reef, Predicted: Hebron\n",
            "Real: Ramallah_Reef, Predicted: Hebron\n",
            "Real: Ramallah_Reef, Predicted: Jerusalem\n",
            "Real: Ramallah_Reef, Predicted: Nablus\n",
            "Real: Ramallah_Reef, Predicted: Hebron\n",
            "Real: Nablus, Predicted: Nablus\n",
            "Real: Nablus, Predicted: Jerusalem\n",
            "Real: Nablus, Predicted: Ramallah_Reef\n",
            "Real: Nablus, Predicted: Hebron\n",
            "Real: Nablus, Predicted: Hebron\n",
            "Real: Jerusalem, Predicted: Hebron\n",
            "Real: Jerusalem, Predicted: Jerusalem\n",
            "Real: Jerusalem, Predicted: Hebron\n",
            "Real: Jerusalem, Predicted: Jerusalem\n",
            "Real: Jerusalem, Predicted: Ramallah_Reef\n",
            "Real: Hebron, Predicted: Hebron\n",
            "Real: Hebron, Predicted: Ramallah_Reef\n",
            "Real: Hebron, Predicted: Hebron\n",
            "Real: Hebron, Predicted: Jerusalem\n",
            "Real: Hebron, Predicted: Hebron\n"
          ]
        }
      ]
    }
  ]
}